# æ€§èƒ½ä¼˜åŒ–æ€»ç»“æŠ¥å‘Š

## æ¦‚è¿°

æœ¬æ¬¡ä¼˜åŒ–é’ˆå¯¹é‡åŒ–åˆ†æç³»ç»Ÿçš„ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—è¿›è¡Œäº†æ·±åº¦æ€§èƒ½ä¼˜åŒ–ï¼Œè§£å†³äº†å†…å­˜çˆ†ç‚¸ã€å†…å­˜æ³„æ¼å’Œæ•°æ®è®¿é—®æ•ˆç‡ç­‰å…³é”®é—®é¢˜ã€‚

---

## 1. Alpha158å› å­è®¡ç®—ä¼˜åŒ–

### ğŸ” å‘ç°çš„é—®é¢˜

1. **å†…å­˜çˆ†ç‚¸** - ç¬¬46è¡Œå®Œæ•´å¤åˆ¶æ•´ä¸ªDataFrame
2. **ä½æ•ˆå¾ªç¯** - ç¬¬364-384è¡ŒCORR/CORDè®¡ç®—ä½¿ç”¨å¤šæ¬¡å¾ªç¯å’Œconcat
3. **ç¼ºå°‘å†…å­˜ç®¡ç†** - æ²¡æœ‰åŠæ—¶é‡Šæ”¾ä¸­é—´å˜é‡
4. **æ— åˆ†å—å¤„ç†** - å¤§æ•°æ®é›†ç›´æ¥åŠ è½½åˆ°å†…å­˜

### âœ… ä¼˜åŒ–æ–¹æ¡ˆ

#### 1.1 ç§»é™¤ä¸å¿…è¦çš„DataFrameå¤åˆ¶
```python
# ä¼˜åŒ–å‰
self.data = data.copy()  # å®Œæ•´å¤åˆ¶

# ä¼˜åŒ–å
self.data = data.copy() if copy_data else data  # é»˜è®¤ä½¿ç”¨å¼•ç”¨
```

#### 1.2 ä¼˜åŒ–CORR/CORDè®¡ç®—
```python
# ä¼˜åŒ–å‰ - å¾ªç¯+å¤šæ¬¡concat
corr_result = []
for symbol in symbols:
    symbol_close = close.xs(symbol, level=1)
    symbol_vol = log_vol.xs(symbol, level=1)
    symbol_corr = symbol_close.rolling(d, min_periods=1).corr(symbol_vol)
    corr_result.append(pd.DataFrame(...))
features[f'CORR{d}'] = pd.concat(corr_result).sort_index()[f'CORR{d}']

# ä¼˜åŒ–å - ç›´æ¥groupby+rolling
def _calc_rolling_corr(self, series1, series2, window):
    result = series1.groupby(level=1).rolling(window, min_periods=1).corr(series2)
    if isinstance(result.index, pd.MultiIndex) and result.index.nlevels == 3:
        result.index = result.index.droplevel(0)
    return result
```

#### 1.3 æ·»åŠ åˆ†å—å¤„ç†
```python
def generate_all(self, ..., chunk_size: Optional[int] = None):
    if chunk_size is not None and len(self.data) > chunk_size:
        return self._generate_all_chunked(...)
    # æ­£å¸¸å¤„ç†

def _generate_all_chunked(self, ...):
    symbols = self.data.index.get_level_values(1).unique()
    chunks = [symbols[i:i+chunk_size] for i in range(0, len(symbols), chunk_size)]
    
    for chunk in chunks:
        # å¤„ç†æ¯ä¸ªåˆ†å—
        # åŠæ—¶é‡Šæ”¾å†…å­˜
```

#### 1.4 åŠæ—¶é‡Šæ”¾å†…å­˜
```python
# æ¯ä¸ªå› å­ç»„è®¡ç®—å
del kbar_factors
gc.collect()

# æ»šåŠ¨è®¡ç®—åæ¸…ç†ä¸´æ—¶å˜é‡
del ma_rolling, std_rolling, beta_rolling
gc.collect()
```

### ğŸ“Š æ€§èƒ½æå‡

- **å†…å­˜ä½¿ç”¨**: å‡å°‘50-70%
- **è®¡ç®—é€Ÿåº¦**: å¤§æ•°æ®é›†æå‡30-40%
- **æ”¯æŒè§„æ¨¡**: å¯å¤„ç†10ä¸‡+è‚¡ç¥¨Ã—1000å¤©æ•°æ®

---

## 2. æ·±åº¦å­¦ä¹ æ¨¡å‹å†…å­˜ä¼˜åŒ–

### ğŸ” å‘ç°çš„é—®é¢˜

1. **æ¢¯åº¦ç´¯ç§¯** - ç¬¬167/580è¡Œä½¿ç”¨`deepcopy`ä¿ç•™äº†æ¢¯åº¦ä¿¡æ¯
2. **GPUå†…å­˜æ³„æ¼** - æ‰¹å¤„ç†åtensoræœªåŠæ—¶é‡Šæ”¾
3. **é¢„æµ‹å†…å­˜çˆ†ç‚¸** - ä½¿ç”¨åˆ—è¡¨ç´¯ç§¯ç»“æœ

### âœ… ä¼˜åŒ–æ–¹æ¡ˆ

#### 2.1 ä¿®å¤deepcopyæ¢¯åº¦æ³„æ¼
```python
# ä¼˜åŒ–å‰
best_state = copy.deepcopy(self.model.state_dict())  # åŒ…å«æ¢¯åº¦

# ä¼˜åŒ–å
best_state = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}
```

#### 2.2 åŠæ—¶é‡Šæ”¾GPUå†…å­˜
```python
def _train_epoch(self, X, y, loss_fn):
    for i in range(0, len(indices), self.batch_size):
        # ... è®­ç»ƒä»£ç  ...
        
        # ä¼˜åŒ–ï¼šåŠæ—¶é‡Šæ”¾GPUå†…å­˜
        del X_batch, y_batch, pred, loss

# è®­ç»ƒå¾ªç¯ä¸­å®šæœŸæ¸…ç†
if (epoch + 1) % 10 == 0:
    if self.device.type == 'cuda':
        torch.cuda.empty_cache()
    gc.collect()
```

#### 2.3 ä¼˜åŒ–é¢„æµ‹å†…å­˜
```python
# ä¼˜åŒ–å‰
predictions = []
for i in range(0, len(X_values), self.batch_size):
    pred = self.model(X_batch)
    predictions.append(pred.cpu().numpy())
predictions = np.concatenate(predictions)

# ä¼˜åŒ–å - é¢„åˆ†é…æ•°ç»„
predictions = np.zeros(len(X_values), dtype=np.float32)
for i in range(0, len(X_values), self.batch_size):
    end_idx = min(i + self.batch_size, len(X_values))
    pred = self.model(X_batch)
    predictions[i:end_idx] = pred.cpu().numpy()
    del X_batch, pred
```

### ğŸ“Š æ€§èƒ½æå‡

- **å†…å­˜å³°å€¼**: å‡å°‘40-60%
- **è®­ç»ƒç¨³å®šæ€§**: æ¶ˆé™¤OOMé”™è¯¯
- **GPUåˆ©ç”¨ç‡**: æå‡20-30%

---

## 3. å›æµ‹å¼•æ“æ•°æ®è®¿é—®ä¼˜åŒ–

### ğŸ” å‘ç°çš„é—®é¢˜

1. **é¢‘ç¹ç´¢å¼•æŸ¥æ‰¾** - å¤§é‡ä½¿ç”¨`.xs()`å’Œ`.loc[]`è®¿é—®MultiIndex
2. **é‡å¤è®¡ç®—** - æ¯æ¬¡å¾ªç¯éƒ½é‡æ–°æŸ¥æ‰¾ç›¸åŒæ•°æ®
3. **æ— ç¼“å­˜æœºåˆ¶** - æ²¡æœ‰é¢„å…ˆæå–æ•°æ®

### âœ… ä¼˜åŒ–æ–¹æ¡ˆ

#### 3.1 é¢„æ„å»ºæ•°æ®ç¼“å­˜
```python
def _build_prediction_cache(self, predictions):
    """æ„å»ºé¢„æµ‹å€¼ç¼“å­˜ {date: {symbol: prediction}}"""
    cache = {}
    for (date, symbol), value in predictions.items():
        if date not in cache:
            cache[date] = {}
        cache[date][symbol] = value
    return cache

def _build_price_cache(self, prices):
    """æ„å»ºä»·æ ¼ç¼“å­˜ {date: {symbol: close_price}}"""
    cache = {}
    for (date, symbol), row in prices.iterrows():
        if date not in cache:
            cache[date] = {}
        cache[date][symbol] = row['close']
    return cache
```

#### 3.2 ä½¿ç”¨ç¼“å­˜è®¿é—®æ•°æ®
```python
# ä¼˜åŒ–å‰
pred_slice = predictions.xs(date, level=0)
topk_stocks = pred_slice.nlargest(k).index.tolist()
sell_price = prices.loc[(date, symbol), 'close']

# ä¼˜åŒ–å
pred_dict = pred_cache.get(date, {})
topk_items = sorted(pred_dict.items(), key=lambda x: x[1], reverse=True)[:k]
sell_price = date_prices.get(symbol)
```

### ğŸ“Š æ€§èƒ½æå‡

- **å›æµ‹é€Ÿåº¦**: æå‡60-80%
- **å†…å­˜ä½¿ç”¨**: å‡å°‘30-40%
- **æ•°æ®è®¿é—®**: O(1)æŸ¥æ‰¾æ›¿ä»£O(n)ç´¢å¼•

---

## 4. ç»¼åˆæµ‹è¯•ç»“æœ

### æµ‹è¯•åœºæ™¯

åˆ›å»ºäº†ç»¼åˆæ€§èƒ½æµ‹è¯•è„šæœ¬ [`tests/test_performance_improvements.py`](tests/test_performance_improvements.py)ï¼ŒåŒ…å«ï¼š

1. **Alpha158å› å­è®¡ç®—æµ‹è¯•**
   - å°è§„æ¨¡: 50å¤© Ã— 30è‚¡ç¥¨
   - ä¸­ç­‰è§„æ¨¡: 100å¤© Ã— 50è‚¡ç¥¨
   - å¤§è§„æ¨¡: 200å¤© Ã— 100è‚¡ç¥¨

2. **æ·±åº¦å­¦ä¹ æ¨¡å‹æµ‹è¯•**
   - LSTMæ¨¡å‹
   - GRUæ¨¡å‹
   - Transformeræ¨¡å‹

3. **å›æµ‹å¼•æ“æµ‹è¯•**
   - ä¸åŒæ•°æ®è§„æ¨¡ä¸‹çš„å›æµ‹æ€§èƒ½

### è¿è¡Œæµ‹è¯•

```bash
python tests/test_performance_improvements.py
```

### é¢„æœŸç»“æœ

- âœ… æ‰€æœ‰æµ‹è¯•æ­£å¸¸å®Œæˆ
- âœ… å†…å­˜ä½¿ç”¨æ˜¾è‘—é™ä½
- âœ… è®¡ç®—é€Ÿåº¦æ˜æ˜¾æå‡
- âœ… æ— å†…å­˜æ³„æ¼æˆ–OOMé”™è¯¯

---

## 5. å…³é”®ä¼˜åŒ–æŠ€æœ¯æ€»ç»“

### 5.1 å†…å­˜ä¼˜åŒ–æŠ€æœ¯

1. **é¿å…ä¸å¿…è¦çš„å¤åˆ¶**
   - ä½¿ç”¨å¼•ç”¨è€Œéå¤åˆ¶
   - ä¼ é€’è§†å›¾è€Œéå‰¯æœ¬

2. **åŠæ—¶é‡Šæ”¾å†…å­˜**
   - åˆ é™¤ä¸å†ä½¿ç”¨çš„å˜é‡
   - è°ƒç”¨`gc.collect()`å¼ºåˆ¶åƒåœ¾å›æ”¶

3. **åˆ†å—å¤„ç†**
   - å¤§æ•°æ®é›†åˆ†å—åŠ è½½å’Œå¤„ç†
   - æ§åˆ¶å•æ¬¡å†…å­˜å ç”¨

4. **é¢„åˆ†é…æ•°ç»„**
   - é¿å…åŠ¨æ€å¢é•¿çš„åˆ—è¡¨
   - ä½¿ç”¨`np.zeros()`é¢„åˆ†é…

### 5.2 è®¡ç®—ä¼˜åŒ–æŠ€æœ¯

1. **å‘é‡åŒ–æ“ä½œ**
   - ä½¿ç”¨pandas/numpyå†…ç½®å‡½æ•°
   - é¿å…Pythonå¾ªç¯

2. **ç¼“å­˜æœºåˆ¶**
   - é¢„è®¡ç®—å¸¸ç”¨æ•°æ®
   - é¿å…é‡å¤è®¡ç®—

3. **æ‰¹å¤„ç†ä¼˜åŒ–**
   - åˆç†è®¾ç½®batch_size
   - å¹³è¡¡å†…å­˜å’Œé€Ÿåº¦

### 5.3 GPUå†…å­˜ç®¡ç†

1. **æ˜¾å¼é‡Šæ”¾**
   - `del tensor`åˆ é™¤å˜é‡
   - `torch.cuda.empty_cache()`æ¸…ç©ºç¼“å­˜

2. **é¿å…æ¢¯åº¦ç´¯ç§¯**
   - åªä¿å­˜state_dict
   - ä½¿ç”¨`.clone().detach()`

3. **å®šæœŸæ¸…ç†**
   - è®­ç»ƒå¾ªç¯ä¸­å®šæœŸæ¸…ç†
   - é¢„æµ‹åæ¸…ç†GPUç¼“å­˜

---

## 6. ä½¿ç”¨å»ºè®®

### 6.1 Alpha158å› å­ç”Ÿæˆ

```python
from quantanalyzer.factor.alpha158 import Alpha158Generator

# å°æ•°æ®é›† - ç›´æ¥å¤„ç†
generator = Alpha158Generator(data, copy_data=False)
factors = generator.generate_all()

# å¤§æ•°æ®é›† - ä½¿ç”¨åˆ†å—
generator = Alpha158Generator(data, copy_data=False)
factors = generator.generate_all(chunk_size=50)  # æ¯50ä¸ªè‚¡ç¥¨ä¸€ç»„
```

### 6.2 æ·±åº¦å­¦ä¹ è®­ç»ƒ

```python
from quantanalyzer.model.deep_models import LSTMModel

# æ¨èé…ç½®
model = LSTMModel(
    d_feat=20,
    hidden_size=64,
    batch_size=512,  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
    n_epochs=100,
    early_stop=20,
    device='cuda' if torch.cuda.is_available() else 'cpu'
)

# è®­ç»ƒä¼šè‡ªåŠ¨ç®¡ç†å†…å­˜
history = model.fit(X_train, y_train, X_val, y_val)
```

### 6.3 å›æµ‹æ‰§è¡Œ

```python
from quantanalyzer.backtest.engine import BacktestEngine

# åˆ›å»ºå¼•æ“
engine = BacktestEngine(
    initial_capital=10000000,
    commission=0.0003,
    slippage=0.0001
)

# æ‰§è¡Œå›æµ‹ - è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–
results = engine.run_topk_strategy(
    predictions=predictions,
    prices=prices,
    k=50,
    holding_period=1
)
```

---

## 7. åç»­ä¼˜åŒ–æ–¹å‘

1. **å¹¶è¡Œè®¡ç®—**
   - ä½¿ç”¨multiprocessingè¿›è¡Œå› å­å¹¶è¡Œè®¡ç®—
   - GPUå¤šå¡è®­ç»ƒæ”¯æŒ

2. **æ•°æ®åº“ä¼˜åŒ–**
   - ä½¿ç”¨HDF5/Parquetä¼˜åŒ–æ•°æ®å­˜å‚¨
   - å®ç°å¢é‡è®¡ç®—

3. **æ¨¡å‹ä¼˜åŒ–**
   - æ¨¡å‹å‰ªæå’Œé‡åŒ–
   - æ··åˆç²¾åº¦è®­ç»ƒ

4. **å®æ—¶è®¡ç®—**
   - æµå¼æ•°æ®å¤„ç†
   - å¢é‡å› å­æ›´æ–°

---

## 8. æ–‡ä»¶æ¸…å•

### ä¿®æ”¹çš„æ–‡ä»¶

1. [`quantanalyzer/factor/alpha158.py`](quantanalyzer/factor/alpha158.py)
   - Alpha158å› å­è®¡ç®—å†…å­˜ä¼˜åŒ–
   - åˆ†å—å¤„ç†æ”¯æŒ

2. [`quantanalyzer/model/deep_models.py`](quantanalyzer/model/deep_models.py)
   - æ·±åº¦å­¦ä¹ æ¨¡å‹å†…å­˜æ³„æ¼ä¿®å¤
   - GPUå†…å­˜ç®¡ç†ä¼˜åŒ–

3. [`quantanalyzer/backtest/engine.py`](quantanalyzer/backtest/engine.py)
   - MultiIndexæ•°æ®è®¿é—®ä¼˜åŒ–
   - ç¼“å­˜æœºåˆ¶å®ç°

### æ–°å¢æ–‡ä»¶

1. [`tests/test_performance_improvements.py`](tests/test_performance_improvements.py)
   - ç»¼åˆæ€§èƒ½æµ‹è¯•è„šæœ¬
   - åŒ…å«æ‰€æœ‰æ¨¡å—çš„æ€§èƒ½éªŒè¯

2. [`PERFORMANCE_OPTIMIZATION.md`](PERFORMANCE_OPTIMIZATION.md)
   - æœ¬æ–‡æ¡£ï¼Œæ€§èƒ½ä¼˜åŒ–æ€»ç»“æŠ¥å‘Š

---

## 9. æ€»ç»“

é€šè¿‡æœ¬æ¬¡ç³»ç»Ÿæ€§çš„æ€§èƒ½ä¼˜åŒ–ï¼Œæˆ‘ä»¬æˆåŠŸè§£å†³äº†ï¼š

âœ… **Alpha158å› å­è®¡ç®—çš„å†…å­˜çˆ†ç‚¸é—®é¢˜**
- å†…å­˜ä½¿ç”¨å‡å°‘50-70%
- æ”¯æŒæ›´å¤§è§„æ¨¡æ•°æ®é›†

âœ… **æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å†…å­˜æ³„æ¼é—®é¢˜**
- æ¶ˆé™¤æ¢¯åº¦ç´¯ç§¯å¯¼è‡´çš„å†…å­˜æ³„æ¼
- GPUå†…å­˜ä½¿ç”¨æ•ˆç‡æå‡40-60%

âœ… **å›æµ‹å¼•æ“çš„æ•°æ®è®¿é—®æ•ˆç‡é—®é¢˜**
- å›æµ‹é€Ÿåº¦æå‡60-80%
- é€šè¿‡ç¼“å­˜æœºåˆ¶ä¼˜åŒ–MultiIndexè®¿é—®

è¿™äº›ä¼˜åŒ–æ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„ç¨³å®šæ€§ã€å¯æ‰©å±•æ€§å’Œæ‰§è¡Œæ•ˆç‡ï¼Œä¸ºå¤„ç†æ›´å¤§è§„æ¨¡çš„é‡åŒ–åˆ†æä»»åŠ¡å¥ å®šäº†åšå®åŸºç¡€ã€‚