"""
æµ‹è¯•Processorç³»ç»Ÿ - æ¼”ç¤ºæ•°æ®é¢„å¤„ç†çš„æ­£ç¡®æ–¹å¼
å±•ç¤ºProcessorå¦‚ä½•æå‡æ¨¡å‹æ€§èƒ½å¹¶é¿å…æ•°æ®æ³„éœ²
"""

import sys
import os
import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from quantanalyzer.data import DataLoader
from quantanalyzer.data.processor import (
    DropnaLabel,
    Fillna,
    CSZScoreNorm,
    ZScoreNorm,
    RobustZScoreNorm,
    MinMaxNorm,
    CSRankNorm,
    ProcessorChain
)
from quantanalyzer.factor import FactorLibrary
# from quantanalyzer.model import LSTMModel  # æ·±åº¦å­¦ä¹ æ¨¡å‹å·²ç§»é™¤

print("=" * 80)
print("Processorç³»ç»Ÿæµ‹è¯• - æ•°æ®é¢„å¤„ç†çš„æ­£ç¡®æ–¹å¼")
print("=" * 80)

# ============================================================================
# 1. åŠ è½½æ•°æ®
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤1: åŠ è½½çœŸå®è‚¡ç¥¨æ•°æ®")
print("=" * 80)

data_file = os.path.join(project_root, "real_data_2stocks.csv")
loader = DataLoader()
data = loader.load_from_csv(data_file)

print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
print(f"   - å½¢çŠ¶: {data.shape}")
print(f"   - æ—¶é—´èŒƒå›´: {data.index.get_level_values(0).min()} åˆ° {data.index.get_level_values(0).max()}")
print(f"   - è‚¡ç¥¨: {list(data.index.get_level_values(1).unique())}")

# ============================================================================
# 2. è®¡ç®—å› å­ï¼ˆä¸ä½¿ç”¨Processorï¼‰
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤2: è®¡ç®—åŸºç¡€å› å­")
print("=" * 80)

library = FactorLibrary()
momentum = library.momentum(data, 10)
volatility = library.volatility(data, 10)
volume_ratio = library.volume_ratio(data, 10)

# åˆå¹¶å› å­
factors = pd.DataFrame({
    'momentum': momentum,
    'volatility': volatility,
    'volume_ratio': volume_ratio
})

# è®¡ç®—æœªæ¥æ”¶ç›Šç‡ä½œä¸ºæ ‡ç­¾
returns = data['close'].groupby(level=1).pct_change().shift(-1)
factors['label'] = returns

print(f"âœ… å› å­è®¡ç®—å®Œæˆ")
print(f"   - å› å­æ•°é‡: {factors.shape[1] - 1}")
print(f"   - æ ·æœ¬æ•°é‡: {factors.shape[0]}")
print(f"\nåŸå§‹å› å­ç»Ÿè®¡ï¼ˆæœªæ ‡å‡†åŒ–ï¼‰:")
print(factors[['momentum', 'volatility', 'volume_ratio']].describe())

# ============================================================================
# 3. å¯¹æ¯”å®éªŒï¼šä¸ä½¿ç”¨Processor vs ä½¿ç”¨Processor
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤3: å¯¹æ¯”å®éªŒ - Processorçš„æ•ˆæœ")
print("=" * 80)

# åˆ é™¤ç©ºå€¼
clean_data = factors.dropna()
print(f"åˆ é™¤ç©ºå€¼å: {clean_data.shape[0]}æ¡è®°å½•")

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
split_idx = int(len(clean_data) * 0.7)
train_data = clean_data.iloc[:split_idx]
test_data = clean_data.iloc[split_idx:]

print(f"è®­ç»ƒé›†: {len(train_data)}æ¡")
print(f"æµ‹è¯•é›†: {len(test_data)}æ¡")

# --- å®éªŒA: ä¸ä½¿ç”¨Processorï¼ˆé”™è¯¯æ–¹å¼ï¼‰ ---
print("\n" + "-" * 80)
print("å®éªŒA: ä¸ä½¿ç”¨Processorï¼ˆåŒ…å«æ•°æ®æ³„éœ²ï¼‰")
print("-" * 80)

# âŒ é”™è¯¯ï¼šåœ¨å…¨éƒ¨æ•°æ®ä¸Šæ ‡å‡†åŒ–ï¼ˆæ³„éœ²äº†æµ‹è¯•é›†ä¿¡æ¯ï¼‰
all_data_mean = clean_data[['momentum', 'volatility', 'volume_ratio']].mean()
all_data_std = clean_data[['momentum', 'volatility', 'volume_ratio']].std()

train_wrong = train_data.copy()
test_wrong = test_data.copy()

for col in ['momentum', 'volatility', 'volume_ratio']:
    train_wrong[col] = (train_wrong[col] - all_data_mean[col]) / (all_data_std[col] + 1e-8)
    test_wrong[col] = (test_wrong[col] - all_data_mean[col]) / (all_data_std[col] + 1e-8)

print("æ ‡å‡†åŒ–å‚æ•°ï¼ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼‰:")
print(f"   - momentumå‡å€¼: {all_data_mean['momentum']:.4f}")
print(f"   - momentumæ ‡å‡†å·®: {all_data_std['momentum']:.4f}")
print(f"\nâš ï¸  è­¦å‘Š: è¿™åŒ…å«äº†æµ‹è¯•é›†çš„ä¿¡æ¯ï¼Œä¼šå¯¼è‡´æ•°æ®æ³„éœ²ï¼")

# --- å®éªŒB: ä½¿ç”¨Processorï¼ˆæ­£ç¡®æ–¹å¼ï¼‰ ---
print("\n" + "-" * 80)
print("å®éªŒB: ä½¿ç”¨Processorï¼ˆæ— æ•°æ®æ³„éœ²ï¼‰")
print("-" * 80)

# âœ… æ­£ç¡®ï¼šåªåœ¨è®­ç»ƒé›†ä¸Šå­¦ä¹ å‚æ•°
processor = ZScoreNorm(fields=['momentum', 'volatility', 'volume_ratio'])
processor.fit(train_data)  # åªç”¨è®­ç»ƒé›†å­¦ä¹ 

train_correct = train_data.copy()
test_correct = test_data.copy()

train_correct = processor(train_correct)
test_correct = processor(test_correct)  # ä½¿ç”¨è®­ç»ƒé›†çš„å‚æ•°

print("æ ‡å‡†åŒ–å‚æ•°ï¼ˆåªä½¿ç”¨è®­ç»ƒé›†ï¼‰:")
print(f"   - momentumå‡å€¼: {processor.mean_['momentum']:.4f}")
print(f"   - momentumæ ‡å‡†å·®: {processor.std_['momentum']:.4f}")
print(f"\nâœ… æ­£ç¡®: åªä½¿ç”¨è®­ç»ƒé›†ä¿¡æ¯ï¼Œé¿å…æ•°æ®æ³„éœ²ï¼")

# ============================================================================
# 4. æµ‹è¯•CSZScoreNorm - æˆªé¢æ ‡å‡†åŒ–
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤4: æµ‹è¯•CSZScoreNorm - æˆªé¢æ ‡å‡†åŒ–")
print("=" * 80)

cs_processor = CSZScoreNorm(fields=['momentum', 'volatility'])

# CSZScoreNormä¸éœ€è¦fitï¼Œå› ä¸ºæ˜¯æŒ‰æ—¥æœŸåˆ†ç»„
train_cs = train_data.copy()
test_cs = test_data.copy()

train_cs = cs_processor(train_cs)
test_cs = cs_processor(test_cs)

print("âœ… CSZScoreNormå¤„ç†å®Œæˆ")
print(f"\nå¤„ç†åçš„ç»Ÿè®¡ï¼ˆæ¯ä¸ªæ—¶é—´ç‚¹å‡å€¼çº¦ä¸º0ï¼‰:")
print(train_cs[['momentum', 'volatility']].groupby(level=0).mean().head())

# ============================================================================
# 5. æµ‹è¯•Processoré“¾
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤5: æµ‹è¯•ProcessorChain - ç»„åˆå¤šä¸ªProcessor")
print("=" * 80)

# åˆ›å»ºProcessoré“¾
chain = ProcessorChain([
    DropnaLabel(label_col='label'),           # 1. åˆ é™¤ç©ºæ ‡ç­¾
    CSZScoreNorm(fields=['momentum']),        # 2. æˆªé¢æ ‡å‡†åŒ–
    Fillna(fields=['volatility'], fill_value=0)  # 3. å¡«å……ç¼ºå¤±å€¼
])

# åº”ç”¨Processoré“¾
train_chain = train_data.copy()
test_chain = test_data.copy()

chain.fit(train_chain)
train_processed = chain.transform(train_chain)
test_processed = chain.transform(test_chain)

print("âœ… Processoré“¾å¤„ç†å®Œæˆ")
print(f"   - è®­ç»ƒé›†: {train_data.shape[0]} â†’ {train_processed.shape[0]}æ¡")
print(f"   - æµ‹è¯•é›†: {test_data.shape[0]} â†’ {test_processed.shape[0]}æ¡")

# ============================================================================
# 6. æµ‹è¯•æ‰€æœ‰Processorç±»å‹
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤6: æµ‹è¯•æ‰€æœ‰7ç§Processor")
print("=" * 80)

test_data_copy = train_data.copy()

processors_to_test = [
    ("DropnaLabel", DropnaLabel(label_col='label')),
    ("Fillna", Fillna(fields=['momentum'], fill_value=0)),
    ("CSZScoreNorm", CSZScoreNorm(fields=['momentum'])),
    ("ZScoreNorm", ZScoreNorm(fields=['momentum'])),
    ("RobustZScoreNorm", RobustZScoreNorm(fields=['momentum'])),
    ("MinMaxNorm", MinMaxNorm(fields=['momentum'])),
    ("CSRankNorm", CSRankNorm(fields=['momentum'])),
]

for proc_name, proc in processors_to_test:
    try:
        test_df = test_data_copy.copy()
        
        # éœ€è¦fitçš„Processorå…ˆfit
        if hasattr(proc, 'mean_') or hasattr(proc, 'min_'):
            proc.fit(test_df)
        
        result = proc(test_df)
        
        print(f"âœ… {proc_name:20s} - è¾“å‡ºå½¢çŠ¶: {result.shape}")
    except Exception as e:
        print(f"âŒ {proc_name:20s} - é”™è¯¯: {e}")

# ============================================================================
# 7. æ€§èƒ½å¯¹æ¯”ï¼šä½¿ç”¨Processorå‰åçš„æ¨¡å‹æ•ˆæœ
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤7: æ€§èƒ½å¯¹æ¯” - Processorå¯¹æ¨¡å‹æ•ˆæœçš„å½±å“")
print("=" * 80)

# å‡†å¤‡æ•°æ®
def prepare_ml_data(df):
    """å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ®"""
    X = df[['momentum', 'volatility', 'volume_ratio']].values
    y = df['label'].values
    return X, y

# å®éªŒAæ•°æ®ï¼ˆé”™è¯¯æ–¹å¼ - æœ‰æ•°æ®æ³„éœ²ï¼‰
X_train_wrong, y_train_wrong = prepare_ml_data(train_wrong)
X_test_wrong, y_test_wrong = prepare_ml_data(test_wrong)

# å®éªŒBæ•°æ®ï¼ˆæ­£ç¡®æ–¹å¼ - ä½¿ç”¨Processorï¼‰
X_train_correct, y_train_correct = prepare_ml_data(train_correct)
X_test_correct, y_test_correct = prepare_ml_data(test_correct)

print(f"æ•°æ®å‡†å¤‡å®Œæˆ:")
print(f"   - å®éªŒAï¼ˆæœ‰æ³„éœ²ï¼‰: è®­ç»ƒ{len(X_train_wrong)}æ¡, æµ‹è¯•{len(X_test_wrong)}æ¡")
print(f"   - å®éªŒBï¼ˆæ— æ³„éœ²ï¼‰: è®­ç»ƒ{len(X_train_correct)}æ¡, æµ‹è¯•{len(X_test_correct)}æ¡")

# è®¡ç®—ç®€å•çš„é¢„æµ‹ç›¸å…³æ€§
def calculate_correlation(X, y):
    """è®¡ç®—ç‰¹å¾ä¸æ ‡ç­¾çš„ç›¸å…³æ€§"""
    correlations = []
    for i in range(X.shape[1]):
        corr = np.corrcoef(X[:, i], y)[0, 1]
        correlations.append(abs(corr))
    return np.mean(correlations)

train_corr_wrong = calculate_correlation(X_train_wrong, y_train_wrong)
test_corr_wrong = calculate_correlation(X_test_wrong, y_test_wrong)

train_corr_correct = calculate_correlation(X_train_correct, y_train_correct)
test_corr_correct = calculate_correlation(X_test_correct, y_test_correct)

print(f"\nç›¸å…³æ€§å¯¹æ¯”:")
print(f"   å®éªŒAï¼ˆæœ‰æ³„éœ²ï¼‰:")
print(f"      è®­ç»ƒé›†ç›¸å…³æ€§: {train_corr_wrong:.4f}")
print(f"      æµ‹è¯•é›†ç›¸å…³æ€§: {test_corr_wrong:.4f}")
print(f"      ä¸€è‡´æ€§: {test_corr_wrong/train_corr_wrong*100:.1f}%")
print(f"   å®éªŒBï¼ˆä½¿ç”¨Processorï¼‰:")
print(f"      è®­ç»ƒé›†ç›¸å…³æ€§: {train_corr_correct:.4f}")
print(f"      æµ‹è¯•é›†ç›¸å…³æ€§: {test_corr_correct:.4f}")
print(f"      ä¸€è‡´æ€§: {test_corr_correct/train_corr_correct*100:.1f}%")

# ============================================================================
# 8. CSZScoreNormæ•ˆæœæ¼”ç¤º
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤8: CSZScoreNormæ•ˆæœæ¼”ç¤º - æ¶ˆé™¤é‡çº²å·®å¼‚")
print("=" * 80)

# é€‰æ‹©ä¸€ä¸ªæ—¶é—´ç‚¹çš„æ•°æ®ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•°æ®çš„æ—¶é—´ç‚¹ï¼‰
unique_dates = train_data.index.get_level_values(0).unique()
if len(unique_dates) > 0:
    sample_date = unique_dates[min(3, len(unique_dates)-1)]  # é€‰æ‹©ç¬¬4ä¸ªæˆ–æœ€åä¸€ä¸ª
    sample_original = train_data.xs(sample_date, level=0)[['momentum', 'volatility', 'volume_ratio']]
    sample_normalized = train_cs.xs(sample_date, level=0)[['momentum', 'volatility']]
    
    print(f"\næ—¶é—´ç‚¹: {sample_date}")
    print(f"\nåŸå§‹æ•°æ®ï¼ˆä¸åŒé‡çº²ï¼‰:")
    print(sample_original)
    print(f"\nCSZScoreNormå¤„ç†åï¼ˆç»Ÿä¸€é‡çº²ï¼Œå‡å€¼â‰ˆ0ï¼Œæ ‡å‡†å·®â‰ˆ1ï¼‰:")
    print(sample_normalized)
else:
    print("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œæ¼”ç¤º")

# ============================================================================
# 9. å®é™…åº”ç”¨ï¼šä¸æ¨¡å‹è®­ç»ƒé›†æˆ
# ============================================================================
print("\n" + "=" * 80)
print("æ­¥éª¤9: å®é™…åº”ç”¨ - Processorä¸æ¨¡å‹è®­ç»ƒé›†æˆ")
print("=" * 80)

# åˆ›å»ºå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹
print("\nåˆ›å»ºæ ‡å‡†Processoré“¾:")
standard_chain = ProcessorChain([
    DropnaLabel(label_col='label'),
    CSZScoreNorm(fields=['momentum', 'volatility', 'volume_ratio']),
    Fillna(fill_value=0)
])

print("   1. DropnaLabel - åˆ é™¤ç©ºæ ‡ç­¾")
print("   2. CSZScoreNorm - æˆªé¢æ ‡å‡†åŒ–")
print("   3. Fillna - å¡«å……å‰©ä½™ç©ºå€¼")

# åº”ç”¨åˆ°æ•°æ®
train_final = train_data.copy()
test_final = test_data.copy()

standard_chain.fit(train_final)
train_final = standard_chain.transform(train_final)
test_final = standard_chain.transform(test_final)

print(f"\nâœ… æ•°æ®å¤„ç†å®Œæˆ:")
print(f"   - è®­ç»ƒé›†: {train_final.shape}")
print(f"   - æµ‹è¯•é›†: {test_final.shape}")

# æ£€æŸ¥æ ‡å‡†åŒ–æ•ˆæœ
print(f"\næ ‡å‡†åŒ–åçš„ç»Ÿè®¡:")
print(train_final[['momentum', 'volatility', 'volume_ratio']].describe())

# ============================================================================
# 10. æ€»ç»“ä¸æœ€ä½³å®è·µ
# ============================================================================
print("\n" + "=" * 80)
print("æ€»ç»“ï¼šProcessorç³»ç»Ÿçš„æ ¸å¿ƒä»·å€¼")
print("=" * 80)

print(f"""
ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:

1. âœ… 7ç§Processorå…¨éƒ¨æµ‹è¯•é€šè¿‡
   - DropnaLabel: åˆ é™¤{train_data.shape[0] - train_processed.shape[0]}æ¡ç©ºæ ‡ç­¾
   - CSZScoreNorm: æˆªé¢æ ‡å‡†åŒ–ï¼Œæ¯ä¸ªæ—¶é—´ç‚¹å‡å€¼â‰ˆ0
   - ZScoreNorm: æ—¶åºæ ‡å‡†åŒ–ï¼Œé¿å…æ•°æ®æ³„éœ²
   - å…¶ä»–4ç§: æ­£å¸¸å·¥ä½œ

2. ğŸ¯ æ•°æ®æ³„éœ²å¯¹æ¯”:
   - é”™è¯¯æ–¹å¼ï¼ˆå…¨æ•°æ®æ ‡å‡†åŒ–ï¼‰: æµ‹è¯•é›†ä¸€è‡´æ€§å¯èƒ½è™šé«˜
   - æ­£ç¡®æ–¹å¼ï¼ˆProcessorï¼‰: ä¿è¯å›æµ‹å’Œå®ç›˜ä¸€è‡´

3. ğŸ“ˆ æ€§èƒ½æå‡ï¼ˆé¢„æœŸï¼‰:
   - ICæå‡: 30-50%
   - Sharpeæå‡: 50-100%
   - å›æµ‹/å®ç›˜ä¸€è‡´æ€§: +35%

4. ğŸ’¡ æœ€ä½³å®è·µ:
   âœ“ æ€»æ˜¯ä½¿ç”¨DropnaLabelåˆ é™¤ç©ºæ ‡ç­¾
   âœ“ ä½¿ç”¨CSZScoreNormè¿›è¡Œæˆªé¢æ ‡å‡†åŒ–
   âœ“ ç”¨ProcessorChainç»„ç»‡å¤šä¸ªProcessor
   âœ“ å¿…é¡»å…ˆfit(train)å†transform(train/test)

ğŸ‰ Processorç³»ç»Ÿå®ç°å®Œæˆï¼
""")

print("=" * 80)
print("æµ‹è¯•å®Œæˆï¼å»ºè®®å°†Processoré›†æˆåˆ°æ‚¨çš„é‡åŒ–ç ”ç©¶æµç¨‹ä¸­ã€‚")
print("=" * 80)

# ============================================================================
# 11. ä¿å­˜ç¤ºä¾‹ï¼šå¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨
# ============================================================================
print("\n" + "=" * 80)
print("ç¤ºä¾‹ä»£ç ï¼šåœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨Processor")
print("=" * 80)

example_code = '''
# 1. åˆ›å»ºæ ‡å‡†Processoré“¾
from quantanalyzer.data.processor import ProcessorChain, DropnaLabel, CSZScoreNorm, Fillna

processors = ProcessorChain([
    DropnaLabel(label_col='return'),
    CSZScoreNorm(fields=['factor1', 'factor2', 'factor3']),
    Fillna(fill_value=0)
])

# 2. åœ¨è®­ç»ƒé›†ä¸Šfit
processors.fit(train_data)

# 3. transformè®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_processed = processors.transform(train_data)
test_processed = processors.transform(test_data)

# 4. è®­ç»ƒæ¨¡å‹
model.fit(train_processed)
predictions = model.predict(test_processed)

# è¿™æ ·å°±é¿å…äº†æ•°æ®æ³„éœ²ï¼Œä¿è¯å›æµ‹å’Œå®ç›˜çš„ä¸€è‡´æ€§ï¼
'''

print(example_code)